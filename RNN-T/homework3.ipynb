{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f45b8fc8b0e64ee1a9296a6cac275f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b726d413daa4dafa661388171fc8813",
              "IPY_MODEL_7fd703594da941d194272bf910b2058c",
              "IPY_MODEL_c0d90040ddbb47cea8dc5f7fd49fcea5"
            ],
            "layout": "IPY_MODEL_39efa0f5e1f64458bd97cfa7331cfbd2"
          }
        },
        "9b726d413daa4dafa661388171fc8813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7768defcfe7646bc9c464756004ed593",
            "placeholder": "​",
            "style": "IPY_MODEL_e402da03abcb4589b21b552f4155419d",
            "value": "100%"
          }
        },
        "7fd703594da941d194272bf910b2058c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dabd7f82d2747d792cea5955f7de4d0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a5d3687c45a439cacabdc2bb788a87c",
            "value": 2
          }
        },
        "c0d90040ddbb47cea8dc5f7fd49fcea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4645482e7e5645929168a9f49c8d8f0c",
            "placeholder": "​",
            "style": "IPY_MODEL_3837fc696228413e975f2be3f6522542",
            "value": " 2/2 [2:40:35&lt;00:00, 4820.87s/it]"
          }
        },
        "39efa0f5e1f64458bd97cfa7331cfbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7768defcfe7646bc9c464756004ed593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e402da03abcb4589b21b552f4155419d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dabd7f82d2747d792cea5955f7de4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5d3687c45a439cacabdc2bb788a87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4645482e7e5645929168a9f49c8d8f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3837fc696228413e975f2be3f6522542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0105406646d4767be9837e83e540904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1c887fa822241458d2ccea1afe58c3d",
              "IPY_MODEL_d89f97bcebcd44049f114422ede40633",
              "IPY_MODEL_3edbbd96b34845229f46693a9f9f98be"
            ],
            "layout": "IPY_MODEL_7020fde6a6fb4d2fb858480b9a1f0849"
          }
        },
        "d1c887fa822241458d2ccea1afe58c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd50cc2e9ae948519fc2198fe2c0b8fe",
            "placeholder": "​",
            "style": "IPY_MODEL_472316585d564b4eafd737b4224197eb",
            "value": "100%"
          }
        },
        "d89f97bcebcd44049f114422ede40633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685a92fddf4b44349badbfdd560f603c",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_391224b0ce194270962e621b53be654d",
            "value": 20
          }
        },
        "3edbbd96b34845229f46693a9f9f98be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb7b6181ad494dfd8795adfb6142694d",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a3a50987804bacb9294364d7f7d4f3",
            "value": " 20/20 [00:12&lt;00:00,  2.92it/s]"
          }
        },
        "7020fde6a6fb4d2fb858480b9a1f0849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd50cc2e9ae948519fc2198fe2c0b8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472316585d564b4eafd737b4224197eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685a92fddf4b44349badbfdd560f603c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391224b0ce194270962e621b53be654d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb7b6181ad494dfd8795adfb6142694d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a3a50987804bacb9294364d7f7d4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f4bad7204347c98cd794ed88a4ff9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54428e04f0014a2baf495dcc909dfa8f",
              "IPY_MODEL_faf8d5cf7f254a64b625c55380bd0a9b",
              "IPY_MODEL_cb211843eac84cf6834ea5ab03442114"
            ],
            "layout": "IPY_MODEL_3017efe450d1444e81c65489719e3f4c"
          }
        },
        "54428e04f0014a2baf495dcc909dfa8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02d748eeb0c4a0e89fe686160b9b7fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f3191f59ea6f42ae8bf1aa96f2b52c26",
            "value": "100%"
          }
        },
        "faf8d5cf7f254a64b625c55380bd0a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ff1f8bb3fe438fbe7eb4aa0bb67c4c",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02b45b2f85a34ab7b7cdde169e074028",
            "value": 20
          }
        },
        "cb211843eac84cf6834ea5ab03442114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d737136e231c4eb58aef111bc9a2d1e0",
            "placeholder": "​",
            "style": "IPY_MODEL_6c56ed86e32b43d8adb87da5be2fd1f0",
            "value": " 20/20 [00:11&lt;00:00,  2.44it/s]"
          }
        },
        "3017efe450d1444e81c65489719e3f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02d748eeb0c4a0e89fe686160b9b7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3191f59ea6f42ae8bf1aa96f2b52c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ff1f8bb3fe438fbe7eb4aa0bb67c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b45b2f85a34ab7b7cdde169e074028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d737136e231c4eb58aef111bc9a2d1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c56ed86e32b43d8adb87da5be2fd1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6578808e3f7942b78e3e55c50ad5bb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c4e77302ebb476e83362e6cc917b54d",
              "IPY_MODEL_9c8c2fdf022846be96c493d0efeaf0ca",
              "IPY_MODEL_0493b5e9a6af413ca8acb5e641fdb137"
            ],
            "layout": "IPY_MODEL_abfd2a60030f4f49a0cdd0fd2a333610"
          }
        },
        "1c4e77302ebb476e83362e6cc917b54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc65be5498a4986ac5d58cf21b2e424",
            "placeholder": "​",
            "style": "IPY_MODEL_95402fc4e7c2437e994cb8b1dfafc504",
            "value": "100%"
          }
        },
        "9c8c2fdf022846be96c493d0efeaf0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f15839bf2ae487d83057a43a78e1cf1",
            "max": 1310,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01c8471902604d95978f8e31e53b4d06",
            "value": 1310
          }
        },
        "0493b5e9a6af413ca8acb5e641fdb137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12fe4d99dd784796a6e4811f168a045e",
            "placeholder": "​",
            "style": "IPY_MODEL_20879855f76f4219804ff2b3447297d3",
            "value": " 1310/1310 [13:16&lt;00:00,  1.33it/s]"
          }
        },
        "abfd2a60030f4f49a0cdd0fd2a333610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc65be5498a4986ac5d58cf21b2e424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95402fc4e7c2437e994cb8b1dfafc504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f15839bf2ae487d83057a43a78e1cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c8471902604d95978f8e31e53b4d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12fe4d99dd784796a6e4811f168a045e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20879855f76f4219804ff2b3447297d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6523c2bf95fc4bffad1a37cb34b1a1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f95014a812464ac3853291c4f56b6881",
              "IPY_MODEL_b79be5bdd6b144c4ac19547689e08d8e"
            ],
            "layout": "IPY_MODEL_f0339d8c4b0045f59919db5878dbd37f"
          }
        },
        "f95014a812464ac3853291c4f56b6881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e38920210f41398d89d4a248608032",
            "placeholder": "​",
            "style": "IPY_MODEL_2ef703d9c273420bbe3545727830066d",
            "value": "128.517 MB of 128.517 MB uploaded\r"
          }
        },
        "b79be5bdd6b144c4ac19547689e08d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681b31dbef4d4d8992b5dd2b57273944",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe16b0ceb66d4b509a0fef6e5845a0a6",
            "value": 1
          }
        },
        "f0339d8c4b0045f59919db5878dbd37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e38920210f41398d89d4a248608032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef703d9c273420bbe3545727830066d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "681b31dbef4d4d8992b5dd2b57273944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe16b0ceb66d4b509a0fef6e5845a0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3: train RNN-T"
      ],
      "metadata": {
        "id": "1LxiMiEui-kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework you will implement a variant of the RNN-T model. For that, you will have to\n",
        "- implement each part of its architecture: Encoder, Predictor, Joiner\n",
        "- implement the greedy decoding algorithm\n",
        "- train your model on a subset of the LibriSpeech corpus"
      ],
      "metadata": {
        "id": "NfPduSa6i-km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup - Install package, download files, etc..."
      ],
      "metadata": {
        "id": "AboXphY7i-kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir files\n",
        "!wget -O files/utils.py https://raw.githubusercontent.com/severilov/DL-Audio-AIMasters-Course/main/seminars/seminar04/files/utils.py"
      ],
      "metadata": {
        "id": "6tO44Q_hi-kp",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9132cd-9ede-48bf-d2cd-cb61f837d644",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:19.820205Z",
          "iopub.execute_input": "2023-11-27T11:25:19.820834Z",
          "iopub.status.idle": "2023-11-27T11:25:22.193700Z",
          "shell.execute_reply.started": "2023-11-27T11:25:19.820802Z",
          "shell.execute_reply": "2023-11-27T11:25:22.192664Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-02 19:34:02--  https://raw.githubusercontent.com/severilov/DL-Audio-AIMasters-Course/main/seminars/seminar04/files/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6770 (6.6K) [text/plain]\n",
            "Saving to: ‘files/utils.py’\n",
            "\n",
            "\rfiles/utils.py        0%[                    ]       0  --.-KB/s               \rfiles/utils.py      100%[===================>]   6.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-02 19:34:02 (89.7 MB/s) - ‘files/utils.py’ saved [6770/6770]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=14vgOVBayQGYv9B1P3hYo3JM56rS6ap3U' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=14vgOVBayQGYv9B1P3hYo3JM56rS6ap3U\" -O files/model_scripted_epoch_5.pt && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "gmrbnsCEi-kq",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e8e92e-22bc-4d7f-a60e-61192b1bf300",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:22.196289Z",
          "iopub.execute_input": "2023-11-27T11:25:22.196695Z",
          "iopub.status.idle": "2023-11-27T11:25:26.211502Z",
          "shell.execute_reply.started": "2023-11-27T11:25:22.196655Z",
          "shell.execute_reply": "2023-11-27T11:25:26.210441Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-02 19:34:02--  https://drive.google.com/uc?export=download&confirm=t&id=14vgOVBayQGYv9B1P3hYo3JM56rS6ap3U\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.202.138, 74.125.202.139, 74.125.202.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.202.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-9s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2h8ngi006g5naiuk01236g7sli52rvtt/1701545625000/02999746975866030610/*/14vgOVBayQGYv9B1P3hYo3JM56rS6ap3U?e=download&uuid=b54341d5-660b-4657-af4b-96bfb9862f4f [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-12-02 19:34:02--  https://doc-0c-9s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2h8ngi006g5naiuk01236g7sli52rvtt/1701545625000/02999746975866030610/*/14vgOVBayQGYv9B1P3hYo3JM56rS6ap3U?e=download&uuid=b54341d5-660b-4657-af4b-96bfb9862f4f\n",
            "Resolving doc-0c-9s-docs.googleusercontent.com (doc-0c-9s-docs.googleusercontent.com)... 209.85.200.132, 2607:f8b0:4001:c16::84\n",
            "Connecting to doc-0c-9s-docs.googleusercontent.com (doc-0c-9s-docs.googleusercontent.com)|209.85.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44610317 (43M) [application/x-zip]\n",
            "Saving to: ‘files/model_scripted_epoch_5.pt’\n",
            "\n",
            "files/model_scripte 100%[===================>]  42.54M   170MB/s    in 0.3s    \n",
            "\n",
            "2023-12-02 19:34:03 (170 MB/s) - ‘files/model_scripted_epoch_5.pt’ saved [44610317/44610317]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb -qqq\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "hcfHw_yWi-kr",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:26.212836Z",
          "iopub.execute_input": "2023-11-27T11:25:26.213133Z",
          "iopub.status.idle": "2023-11-27T11:25:49.824669Z",
          "shell.execute_reply.started": "2023-11-27T11:25:26.213104Z",
          "shell.execute_reply": "2023-11-27T11:25:49.823385Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "from typing import Tuple, List, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import wandb\n",
        "import ipywidgets as widgets\n",
        "import itertools\n",
        "from torch import optim\n",
        "from torchaudio.transforms import RNNTLoss\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "4u_exS1ii-ks",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:49.827568Z",
          "iopub.execute_input": "2023-11-27T11:25:49.827873Z",
          "iopub.status.idle": "2023-11-27T11:25:53.957492Z",
          "shell.execute_reply.started": "2023-11-27T11:25:49.827843Z",
          "shell.execute_reply": "2023-11-27T11:25:53.956683Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import files.utils as utils"
      ],
      "metadata": {
        "id": "VceAkujPi-ks",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:53.958504Z",
          "iopub.execute_input": "2023-11-27T11:25:53.958765Z",
          "iopub.status.idle": "2023-11-27T11:25:53.965213Z",
          "shell.execute_reply.started": "2023-11-27T11:25:53.958741Z",
          "shell.execute_reply": "2023-11-27T11:25:53.964359Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot_dir = \"rnn_t_snapshots\""
      ],
      "metadata": {
        "id": "n14D_Nzei-ks",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:53.967677Z",
          "iopub.execute_input": "2023-11-27T11:25:53.968273Z",
          "iopub.status.idle": "2023-11-27T11:25:53.974340Z",
          "shell.execute_reply.started": "2023-11-27T11:25:53.968240Z",
          "shell.execute_reply": "2023-11-27T11:25:53.973513Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir rnn_t_snapshots"
      ],
      "metadata": {
        "id": "txn-Rm7Si-kt",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:53.975452Z",
          "iopub.execute_input": "2023-11-27T11:25:53.975697Z",
          "iopub.status.idle": "2023-11-27T11:25:54.923987Z",
          "shell.execute_reply.started": "2023-11-27T11:25:53.975675Z",
          "shell.execute_reply": "2023-11-27T11:25:54.922729Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seminar 4 RECAP: RNN-T Forward-Backward Algorithm"
      ],
      "metadata": {
        "id": "o8kaGJYEi-kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In seminar 4 we have implememented forward and backward algorithms for calculating the RNN-T loss."
      ],
      "metadata": {
        "id": "HoVISxSCt3OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(log_probs: torch.FloatTensor, targets: torch.LongTensor,\n",
        "            blank: int = -1) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "    \"\"\"\n",
        "    :param log_probs: model outputs after applying log_softmax\n",
        "    :param targets: the target sequence of tokens, represented as integer indexes\n",
        "    :param blank: the index of blank symbol\n",
        "    :return: Tuple[ln alpha, -(ln alpha(T, U) + ln P(blank | T, U))].\n",
        "        The latter term is loss value, which is -ln P(y | x)\n",
        "    \"\"\"\n",
        "    max_T, max_U, D = log_probs.shape\n",
        "\n",
        "    # here the alpha variable contains logarithm of the alpha variable from the formulas above\n",
        "    alpha = np.zeros((max_T, max_U), dtype=np.float32)\n",
        "\n",
        "    for t in range(1, max_T):\n",
        "        alpha[t, 0] = alpha[t-1, 0] + log_probs[t-1, 0, blank]\n",
        "\n",
        "    for u in range(1, max_U):\n",
        "        alpha[0, u] = alpha[0, u-1] + log_probs[0, u-1, targets[min(u-1, len(targets)-1)]]\n",
        "\n",
        "    for t in range(1, max_T):\n",
        "        for u in range(1, max_U):\n",
        "            alpha[t, u] =  np.logaddexp(\n",
        "                alpha[t-1, u] + log_probs[t-1, u, blank],\n",
        "                alpha[t, u-1] + log_probs[t, u-1, targets[min(u-1, len(targets)-1)]]\n",
        "            )\n",
        "\n",
        "    cost = - (log_probs[-1, -1, blank] + alpha[-1, -1])\n",
        "    return alpha, cost\n",
        "\n",
        "\n",
        "def backward(log_probs: torch.FloatTensor, targets: torch.LongTensor,\n",
        "             blank: int = -1) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "    \"\"\"\n",
        "    :param log_probs: model outputs after applying log_softmax\n",
        "    :param targets: the target sequence of tokens, represented as integer indexes\n",
        "    :param blank: the index of blank symbol\n",
        "    :return: Tuple[ln beta, -ln beta(0, 0)]. The latter term is loss value, which is -ln P(y | x)\n",
        "    \"\"\"\n",
        "    max_T, max_U, D = log_probs.shape\n",
        "\n",
        "    # here the beta variable contains logarithm of the beta variable from the formulas above\n",
        "    beta = np.zeros((max_T, max_U), dtype=np.float32)\n",
        "    beta[-1, -1] = log_probs[-1, -1, blank]\n",
        "\n",
        "    for t in reversed(range(max_T - 1)):\n",
        "        beta[t, max_U-1] = beta[t+1, max_U-1] + log_probs[t, max_U-1, blank]\n",
        "\n",
        "    for u in reversed(range(max_U - 1)):\n",
        "        beta[max_T-1, u] = beta[max_T-1, u+1] + log_probs[max_T-1, u, targets[min(u, len(targets)-1)]]\n",
        "\n",
        "    for t in reversed(range(max_T - 1)):\n",
        "        for u in reversed(range(max_U - 1)):\n",
        "            beta[t, u] =  np.logaddexp(\n",
        "                beta[t+1, u] + log_probs[t, u, blank],\n",
        "                beta[t, u+1] + log_probs[t, u, targets[min(u, len(targets)-1)]]\n",
        "            )\n",
        "\n",
        "    cost = - beta[0, 0]\n",
        "    return beta, cost"
      ],
      "metadata": {
        "id": "EcM082LQi-kz",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:54.925491Z",
          "iopub.execute_input": "2023-11-27T11:25:54.925777Z",
          "iopub.status.idle": "2023-11-27T11:25:54.943387Z",
          "shell.execute_reply.started": "2023-11-27T11:25:54.925750Z",
          "shell.execute_reply": "2023-11-27T11:25:54.942499Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing, training and evaluating your RNN-T ASR model (40 points)"
      ],
      "metadata": {
        "id": "e-Kcnm7Ki-k1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "[ ] (15 points) Build the model\n",
        "[ ] (15 points) Implementing a greedy decoder\n",
        "[ ] (10 points) Train the model\n",
        "```"
      ],
      "metadata": {
        "id": "u7_XForhi-k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLANK_SYMBOL = \"_\"\n",
        "BOS = \"<BOS>\"\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    \"\"\"\n",
        "    Maps characters to integers and vice versa\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for i, ch in enumerate([\"'\", \" \"] + list(string.ascii_lowercase) + [BLANK_SYMBOL, BOS]):\n",
        "            self.char_map[ch] = i\n",
        "            self.index_map[i] = ch\n",
        "\n",
        "    def text_to_indices(self, text: str) -> List[int]:\n",
        "        \"\"\"\n",
        "        Maps string to a list of integers\n",
        "        \"\"\"\n",
        "        return [self.char_map[ch] for ch in text]\n",
        "\n",
        "    def indices_to_text(self, labels: List[int]) -> str:\n",
        "        \"\"\"\n",
        "        Maps integers back to text\n",
        "        \"\"\"\n",
        "        return \"\".join([self.index_map[i] for i in labels])\n",
        "\n",
        "    def get_symbol_index(self, sym: str) -> int:\n",
        "        \"\"\"\n",
        "        Returns index for the specified symbol\n",
        "        \"\"\"\n",
        "        return self.char_map[sym]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "TIy1M2ICi-k1",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:54.944503Z",
          "iopub.execute_input": "2023-11-27T11:25:54.944747Z",
          "iopub.status.idle": "2023-11-27T11:25:54.958039Z",
          "shell.execute_reply.started": "2023-11-27T11:25:54.944725Z",
          "shell.execute_reply": "2023-11-27T11:25:54.957201Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils for creating a dataloader"
      ],
      "metadata": {
        "id": "t_QF8XMBi-k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download LibriSpeech 100hr training and test data\n",
        "\n",
        "if not os.path.isdir(\"./data\"):\n",
        "    os.makedirs(\"./data\")\n",
        "\n",
        "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\n",
        "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)"
      ],
      "metadata": {
        "id": "L_Xmk902i-k2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850e16fc-9ba1-4558-8eb3-c35883b74f35",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:25:54.962533Z",
          "iopub.execute_input": "2023-11-27T11:25:54.962781Z",
          "iopub.status.idle": "2023-11-27T11:34:09.352883Z",
          "shell.execute_reply.started": "2023-11-27T11:25:54.962759Z",
          "shell.execute_reply": "2023-11-27T11:34:09.352052Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.95G/5.95G [03:49<00:00, 27.8MB/s]\n",
            "100%|██████████| 331M/331M [00:12<00:00, 28.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For train you can use SpecAugment data aug here.\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=27),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "test_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=80)"
      ],
      "metadata": {
        "id": "mLWxbcjMi-k2",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:09.354083Z",
          "iopub.execute_input": "2023-11-27T11:34:09.354384Z",
          "iopub.status.idle": "2023-11-27T11:34:09.485349Z",
          "shell.execute_reply.started": "2023-11-27T11:34:09.354346Z",
          "shell.execute_reply": "2023-11-27T11:34:09.484559Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_processing(data: torchaudio.datasets.librispeech.LIBRISPEECH,\n",
        "                    data_type: str = \"train\") -> Tuple[torch.Tensor, torch.IntTensor, torch.IntTensor, torch.IntTensor]:\n",
        "    \"\"\"\n",
        "    :param data: a LIBRISPEECH dataset\n",
        "    :param data_type: \"train\" or \"test\"\n",
        "    :return: tuple of\n",
        "        spectrograms, shape: (B, T, n_mels)\n",
        "        labels, shape: (B, U)\n",
        "        input_lengths -- the length of each spectrogram in the batch, shape: (B,)\n",
        "        label_lengths -- the length of each text label in the batch, shape: (B,)\n",
        "        where\n",
        "        B: batch size\n",
        "        T: maximum source sequence length in batch\n",
        "        U: maximum target sequence length in batch\n",
        "        D: feature dimension of each source sequence element\n",
        "    \"\"\"\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'test':\n",
        "            spec = test_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.IntTensor(tokenizer.text_to_indices(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0])\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, torch.IntTensor(labels), torch.IntTensor(input_lengths), torch.IntTensor(label_lengths)\n"
      ],
      "metadata": {
        "id": "cLsCL472i-k2",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:09.488502Z",
          "iopub.execute_input": "2023-11-27T11:34:09.489588Z",
          "iopub.status.idle": "2023-11-27T11:34:09.500163Z",
          "shell.execute_reply.started": "2023-11-27T11:34:09.489551Z",
          "shell.execute_reply": "2023-11-27T11:34:09.499228Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model (15 points)"
      ],
      "metadata": {
        "id": "1SbrcCk6i-k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class EncoderRNNT(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_size: int, output_dim: int, n_layers: int,\n",
        "                 dropout: float = 0.2, bidirectional: bool = True):\n",
        "        \"\"\"\n",
        "        An RNN-based model that encodes input audio features into a hidden representation.\n",
        "        The architecture is a stack of LSTM's followed by a fully-connected output layer.\n",
        "\n",
        "        :param input_dim: the number of mel-spectrogram features\n",
        "        :param hidden_size: the number of features in the hidden states in LSTM layers\n",
        "        :param output_dim: the output dimension\n",
        "        :param n_layers: the number of stacked LSTM layers\n",
        "        :param dropout: the dropout probability for LSTM layers\n",
        "        :param bidirectional: If True, each LSTM layer becomes bidirectional\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers=n_layers,\n",
        "                            dropout=dropout, bidirectional=bidirectional) # <YOUR CODE>\n",
        "\n",
        "        self.output_proj = nn.Linear(2 * hidden_size if bidirectional else hidden_size, output_dim) # <YOUR CODE>\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, input_lengths: torch.Tensor) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        :param inputs: spectrograms, shape: (B, T, n_mels)\n",
        "        :param input_lengths: the lengths of the spectrograms in the batch, shape: (B,)\n",
        "        :return: outputs of the projection layer and hidden states from LSTMs\n",
        "        \"\"\"\n",
        "        # <YOUR CODE>\n",
        "        packed = pack_padded_sequence(inputs, input_lengths, batch_first=True, enforce_sorted=False)\n",
        "        out, hidden = self.lstm(packed)\n",
        "        out, _ = pad_packed_sequence(out, batch_first=True)\n",
        "        logits = self.output_proj(out)\n",
        "\n",
        "        return logits, hidden"
      ],
      "metadata": {
        "id": "y57EYzcgi-k3",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:09.501340Z",
          "iopub.execute_input": "2023-11-27T11:34:09.501641Z",
          "iopub.status.idle": "2023-11-27T11:34:09.516913Z",
          "shell.execute_reply.started": "2023-11-27T11:34:09.501617Z",
          "shell.execute_reply": "2023-11-27T11:34:09.516154Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = EncoderRNNT(\n",
        "    input_dim=80,\n",
        "    hidden_size=320,\n",
        "    output_dim=512,\n",
        "    n_layers=4,\n",
        "    dropout=0.2,\n",
        "    bidirectional=True\n",
        ")\n",
        "\n",
        "loader = data.DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: data_processing(x, 'test'))\n",
        "spectrograms, labels, input_lengths, label_lengths = next(iter(loader))\n",
        "logits, hidden_states = encoder.forward(spectrograms, input_lengths)\n",
        "\n",
        "assert spectrograms.shape == torch.Size([2, 835, 80])\n",
        "assert logits.shape == torch.Size([2, 835, 512])\n",
        "assert len(hidden_states) == 2\n",
        "assert hidden_states[0].shape == torch.Size([8, 2, 320])"
      ],
      "metadata": {
        "id": "tCeaQG-2i-k4",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:09.518047Z",
          "iopub.execute_input": "2023-11-27T11:34:09.518617Z",
          "iopub.status.idle": "2023-11-27T11:34:10.573203Z",
          "shell.execute_reply.started": "2023-11-27T11:34:09.518585Z",
          "shell.execute_reply": "2023-11-27T11:34:10.572384Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNNT(nn.Module):\n",
        "    def __init__(self, hidden_size: int, vocab_size: int, output_dim: int, n_layers: int, dropout: float = 0.2):\n",
        "        \"\"\"\n",
        "        A simple RNN-based autoregressive language model that takes as input previously generated text tokens\n",
        "        and outputs a hidden representation of the next token\n",
        "\n",
        "        :param hidden_size: the number of features in the hidden states in LSTM layers\n",
        "        :param vocab_size: the number of text tokens in the dictionary\n",
        "        :param output_dim: the output dimension\n",
        "        :param n_layers: the number of stacked LSTM layers\n",
        "        :param dropout: the dropout probability for LSTM layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size) # <YOUR CODE>\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, dropout=dropout) # <YOUR CODE>\n",
        "        self.output_proj = nn.Linear(hidden_size, output_dim) # <YOUR CODE>\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, input_lengths: Optional[torch.Tensor] = None,\n",
        "                hidden_states: Optional[Tuple[torch.Tensor, torch.Tensor]] = None) -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        :param inputs: labels, shape: (B, U)\n",
        "        :param input_lengths: the lengths of the text labels in the batch, shape: (B,)\n",
        "        :return: outputs of the projection layer and hidden states from LSTMs\n",
        "        \"\"\"\n",
        "        embed_inputs = self.embedding(inputs) # <YOUR CODE>\n",
        "\n",
        "        if input_lengths is not None:\n",
        "            # training phase, the code here is close to `forward` of the Encoder\n",
        "            # <YOUR CODE>\n",
        "            packed = pack_padded_sequence(embed_inputs, input_lengths, batch_first=True, enforce_sorted=False)\n",
        "            outputs, hidden = self.lstm(packed)\n",
        "            outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "        else:\n",
        "            # testing phase\n",
        "            outputs, hidden = self.lstm(embed_inputs, hidden_states)\n",
        "\n",
        "        outputs = self.output_proj(outputs)\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "bhLTyplNi-k4",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:10.574587Z",
          "iopub.execute_input": "2023-11-27T11:34:10.575164Z",
          "iopub.status.idle": "2023-11-27T11:34:10.585198Z",
          "shell.execute_reply.started": "2023-11-27T11:34:10.575128Z",
          "shell.execute_reply": "2023-11-27T11:34:10.584310Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = DecoderRNNT(\n",
        "    hidden_size=512,\n",
        "    vocab_size=len(tokenizer.char_map),\n",
        "    output_dim=512,\n",
        "    n_layers=1,\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "loader = data.DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: data_processing(x, 'test'))\n",
        "spectrograms, labels, input_lengths, label_lengths = next(iter(loader))\n",
        "logits, hidden_states = decoder.forward(labels, label_lengths)\n",
        "\n",
        "assert labels.shape == torch.Size([2, 158])\n",
        "assert logits.shape == torch.Size([2, 158, 512])\n",
        "assert len(hidden_states) == 2\n",
        "assert hidden_states[0].shape == torch.Size([1, 2, 512])"
      ],
      "metadata": {
        "id": "QNGRqpMji-k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266c3e88-f061-42a2-ff20-6163a795a282",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:10.586333Z",
          "iopub.execute_input": "2023-11-27T11:34:10.586628Z",
          "iopub.status.idle": "2023-11-27T11:34:10.755611Z",
          "shell.execute_reply.started": "2023-11-27T11:34:10.586603Z",
          "shell.execute_reply": "2023-11-27T11:34:10.754603Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Joiner(torch.nn.Module):\n",
        "    def __init__(self, joiner_dim: int, num_outputs: int):\n",
        "        \"\"\"\n",
        "        Adds encoder and decoder outputs, applies ReLU and passes the result\n",
        "        through a fully connected layer to get the output logits\n",
        "\n",
        "        :param joiner_dim: the dimension of the encoder and decoder outputs\n",
        "        :num_outputs: the number of text tokens in the dictionary\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(joiner_dim, num_outputs) # <YOUR CODE>\n",
        "\n",
        "    def forward(self, encoder_outputs: torch.Tensor, decoder_outputs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param encoder_outputs: the encoder outputs (f_t), shape: (B, T, joiner_dim) or (joiner_dim,)\n",
        "        :param decoder_outputs: the decoder outputs (g_u), shape: (B, U, joiner_dim) or (joiner_dim,)\n",
        "        :return: output logits\n",
        "        \"\"\"\n",
        "        if encoder_outputs.dim() == 3 and decoder_outputs.dim() == 3:    # True for training phase\n",
        "            encoder_outputs = encoder_outputs.unsqueeze(2)\n",
        "            decoder_outputs = decoder_outputs.unsqueeze(1)\n",
        "\n",
        "        # Linear(ReLU(f_t + g_u))\n",
        "        out = F.relu(self.linear(encoder_outputs + decoder_outputs)) # <YOUR CODE>\n",
        "        return out"
      ],
      "metadata": {
        "id": "IaM_Tkzhi-k5",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:10.757239Z",
          "iopub.execute_input": "2023-11-27T11:34:10.757638Z",
          "iopub.status.idle": "2023-11-27T11:34:10.765142Z",
          "shell.execute_reply.started": "2023-11-27T11:34:10.757598Z",
          "shell.execute_reply": "2023-11-27T11:34:10.764296Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNTransducer(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "        num_classes: int,\n",
        "        input_dim: int,\n",
        "        num_encoder_layers: int = 4,\n",
        "        num_decoder_layers: int = 1,\n",
        "        encoder_hidden_state_dim: int = 320,\n",
        "        decoder_hidden_state_dim: int = 512,\n",
        "        output_dim: int = 512,\n",
        "        encoder_is_bidirectional: bool = True,\n",
        "        encoder_dropout_p: float = 0.2,\n",
        "        decoder_dropout_p: float = 0.2\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param num_classes: the number of text tokens in the dictionary\n",
        "        :param input_dim: the number of mel-spectrogram features\n",
        "        :param num_encoder_layers: the number of LSTM layers in the encoder\n",
        "        :param num_decoder_layers: the number of LSTM layers in the decoder\n",
        "        :param encoder_hidden_state_dim: the number of features in the hidden states for the encoder\n",
        "        :param decoder_hidden_state_dim: the number of features in the hidden states for the decoder\n",
        "        :param output_dim: the output dimension\n",
        "        :param encoder_is_bidirectional: whether to use bidirectional LSTM's in the encoder\n",
        "        :param encoder_dropout_p: the dropout probability for the encoder\n",
        "        :param decoder_dropout_p: the dropout probability for the decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderRNNT(input_dim, encoder_hidden_state_dim, output_dim, num_encoder_layers,\n",
        "                                   encoder_dropout_p, encoder_is_bidirectional) # <YOUR CODE>\n",
        "\n",
        "        # The decoder takes the input <BOS> + the original sequence.\n",
        "        # You need to shift the current label, and F.pad can help with that.\n",
        "        self.decoder = DecoderRNNT(decoder_hidden_state_dim, num_classes, output_dim,\n",
        "                                   num_decoder_layers, decoder_dropout_p) # <YOUR CODE>\n",
        "        self.joiner = Joiner(output_dim, num_classes) # <YOUR CODE>\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, input_lengths: torch.Tensor,\n",
        "                targets: torch.Tensor, target_lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param inputs: spectrograms, shape: (B, T, n_mels)\n",
        "        :param input_lengths: the lengths of the spectrograms in the batch, shape: (B,)\n",
        "        :param targets: labels, shape: (B, U)\n",
        "        :param target_lengths: the lengths of the text labels in the batch, shape: (B,)\n",
        "        :return: the output logits, shape: (B, T, U, n_tokens)\n",
        "        \"\"\"\n",
        "        encoder_outputs, _ = self.encoder(inputs, input_lengths) # <YOUR CODE>\n",
        "        decoder_outputs, _ = self.decoder(F.pad(targets, (1, 0, 0, 0), value=tokenizer.char_map['<BOS>']),\n",
        "                                          target_lengths + 1) # <YOUR CODE>\n",
        "        joiner_out = self.joiner(encoder_outputs, decoder_outputs) # <YOUR CODE>\n",
        "        return joiner_out\n"
      ],
      "metadata": {
        "id": "ovd_OawAi-k5",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:10.766712Z",
          "iopub.execute_input": "2023-11-27T11:34:10.767092Z",
          "iopub.status.idle": "2023-11-27T11:34:10.780450Z",
          "shell.execute_reply.started": "2023-11-27T11:34:10.767029Z",
          "shell.execute_reply": "2023-11-27T11:34:10.779580Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transducer = RNNTransducer(\n",
        "    num_classes=len(tokenizer.char_map),\n",
        "    input_dim=80,\n",
        "    num_encoder_layers=4,\n",
        "    num_decoder_layers=1,\n",
        "    encoder_hidden_state_dim=320,\n",
        "    decoder_hidden_state_dim=512,\n",
        "    output_dim=512,\n",
        "    encoder_is_bidirectional=True,\n",
        "    encoder_dropout_p=0.2,\n",
        "    decoder_dropout_p=0.2\n",
        ")\n",
        "\n",
        "loader = data.DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: data_processing(x, 'test'))\n",
        "spectrograms, labels, input_lengths, label_lengths = next(iter(loader))\n",
        "result = transducer.forward(spectrograms, input_lengths, labels, label_lengths)\n",
        "\n",
        "assert spectrograms.shape == torch.Size([2, 835, 80])\n",
        "assert labels.shape == torch.Size([2, 158])\n",
        "assert result.shape == torch.Size([2, 835, 159, 30])"
      ],
      "metadata": {
        "id": "PnC5EE33i-k6",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:10.781546Z",
          "iopub.execute_input": "2023-11-27T11:34:10.781822Z",
          "iopub.status.idle": "2023-11-27T11:34:12.003731Z",
          "shell.execute_reply.started": "2023-11-27T11:34:10.781798Z",
          "shell.execute_reply": "2023-11-27T11:34:12.002756Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a greedy decoder (15 points)"
      ],
      "metadata": {
        "id": "qBdlLxKni-k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1tHsoq0ZH0tHSHYlYlw00y8ksF-wHmrmC\">"
      ],
      "metadata": {
        "id": "RPZv4-Bdi-k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we know how to train a Transducer, but how do we infer it? Our task is to generate an output sequence $\\mathbf y$ given an input acoustic sequence $\\mathbf x$.\n",
        "\n",
        "Here we will index the encoder outputs $f_t$ starting from zero, because it is more convenient when describing an algorithm.\n",
        "\n",
        "The greedy decoding procedure is as follows:\n",
        "1. Compute $\\{f_0, \\ldots, f_T\\}$ using $\\mathbf x$.\n",
        "2. Set $t = 0$, $u = 0$, $\\mathbf y = []$, $\\mathrm{iteration} = 0$.\n",
        "3. If $u = 0$, set $g_0 = \\mathrm{Encoder}(\\langle s \\rangle)$. If $u > 0$, compute $g_u$ using the last predicted token $\\mathbf y[-1]$.\n",
        "4. Compute $P(y | t, u)$ using $f_t$ and $g_u$.\n",
        "5. If argmax of $P(y | t, u)$ is a label, set $u = u + 1$ and append the new label to $\\mathbf y$.\n",
        "6. If argmax of $P(y | t, u)$ is $\\emptyset$, set $t = t + 1$.\n",
        "7. If $t = T$ or $\\mathrm{iteration} = \\mathrm{max\\_iterations}$, we are done. Else, set $\\mathrm{iteration} = \\mathrm{iteration + 1}$ and go to step 3."
      ],
      "metadata": {
        "id": "wMhA58FEi-k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.text import char_error_rate as cer\n",
        "from torchmetrics.functional.text import word_error_rate as wer\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_decode(model: RNNTransducer, encoder_output: torch.Tensor, max_steps: int = 2000) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    :param model: an RNN-T model in eval mode\n",
        "    :param encoder_output: the output of the encoder part of RNN-T, shape: (T, encoder_output_dim)\n",
        "    :param max_steps: the maximum number of decoding steps\n",
        "    :return: the predicted labels\n",
        "    \"\"\"\n",
        "    pred_tokens, hidden_state = [], None\n",
        "    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n",
        "    max_time_steps = encoder_output.size(0)\n",
        "    t = 0\n",
        "    u = 0\n",
        "\n",
        "    decoder_input = encoder_output.new_tensor([[tokenizer.get_symbol_index(BOS)]], dtype=torch.long)\n",
        "    decoder_output, hidden_state = model.decoder(decoder_input, hidden_states=hidden_state)\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        # <YOUR CODE>\n",
        "        prob = model.joiner(encoder_output.unsqueeze(0), decoder_output)\n",
        "        argmax_prob = prob[0, t, 0, :].argmax().item()\n",
        "\n",
        "        if argmax_prob == blank:\n",
        "            t += 1\n",
        "        else:\n",
        "            u += 1\n",
        "            pred_tokens.append(argmax_prob)\n",
        "            decoder_input = encoder_output.new_tensor([[pred_tokens[-1]]], dtype=torch.long)\n",
        "            decoder_output, hidden_state = model.decoder(decoder_input, hidden_states=hidden_state)\n",
        "\n",
        "        if t == max_time_steps:\n",
        "            break\n",
        "\n",
        "    return torch.LongTensor(pred_tokens)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def recognize(model: RNNTransducer, inputs: torch.Tensor, input_lengths: torch.Tensor) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    :param model: an RNN-T model in eval mode\n",
        "    :param inputs: spectrograms, shape: (B, T, n_mels)\n",
        "    :param input_lengths: the lengths of the spectrograms in the batch, shape: (B,)\n",
        "    :return: a list with the predicted labels\n",
        "    \"\"\"\n",
        "    outputs = []\n",
        "    encoder_outputs, _ = model.encoder(inputs, input_lengths)\n",
        "\n",
        "    for encoder_output in encoder_outputs:\n",
        "        decoded_seq = greedy_decode(model, encoder_output)\n",
        "        outputs.append(decoded_seq)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def get_transducer_predictions(\n",
        "        transducer: RNNTransducer, inputs: torch.Tensor, input_lengths: torch.Tensor,\n",
        "        targets: torch.Tensor, target_lengths: torch.Tensor\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    :param transducer: an RNN-T model in eval mode\n",
        "    :param inputs: spectrograms, shape: (B, T, n_mels)\n",
        "    :param input_lengths: the lengths of the spectrograms in the batch, shape: (B,)\n",
        "    :param targets: labels, shape: (B, U)\n",
        "    :param target_lengths: the lengths of the text labels in the batch, shape: (B,)\n",
        "    :return: a pd.DataFrame with inference results\n",
        "    \"\"\"\n",
        "    predictions = recognize(transducer, inputs, input_lengths)\n",
        "    result = []\n",
        "    for pred, target, target_len in zip(predictions, targets, target_lengths):\n",
        "        label = target[:target_len]\n",
        "        utterance = tokenizer.indices_to_text(list(map(int, label)))\n",
        "        pred_utterance = tokenizer.indices_to_text(list(map(int, pred)))\n",
        "        result.append({\n",
        "            \"ground_truth\": utterance,\n",
        "            \"prediction\": pred_utterance,\n",
        "#             \"cer\": utils.cer(utterance, pred_utterance),\n",
        "#             \"wer\": utils.wer(utterance, pred_utterance)\n",
        "            \"cer\": cer(utterance, pred_utterance).item(),\n",
        "            \"wer\": wer(utterance, pred_utterance).item()\n",
        "        })\n",
        "    return pd.DataFrame.from_records(result)\n"
      ],
      "metadata": {
        "id": "o3tjfGsji-k7",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:12.005416Z",
          "iopub.execute_input": "2023-11-27T11:34:12.005799Z",
          "iopub.status.idle": "2023-11-27T11:34:14.405195Z",
          "shell.execute_reply.started": "2023-11-27T11:34:12.005765Z",
          "shell.execute_reply": "2023-11-27T11:34:14.404419Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load('files/model_scripted_epoch_5.pt')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "FIJtZpE3i-k7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daea0a4a-46df-476f-9580-74d5e6bff0a1",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:14.406525Z",
          "iopub.execute_input": "2023-11-27T11:34:14.407130Z",
          "iopub.status.idle": "2023-11-27T11:34:14.764847Z",
          "shell.execute_reply.started": "2023-11-27T11:34:14.407091Z",
          "shell.execute_reply": "2023-11-27T11:34:14.763943Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(\n",
              "  original_name=RNNTransducer\n",
              "  (encoder): RecursiveScriptModule(\n",
              "    original_name=EncoderRNNT\n",
              "    (lstm): RecursiveScriptModule(original_name=LSTM)\n",
              "    (output_proj): RecursiveScriptModule(original_name=Linear)\n",
              "  )\n",
              "  (decoder): RecursiveScriptModule(\n",
              "    original_name=DecoderRNNT\n",
              "    (embedding): RecursiveScriptModule(original_name=Embedding)\n",
              "    (lstm): RecursiveScriptModule(original_name=LSTM)\n",
              "    (output_proj): RecursiveScriptModule(original_name=Linear)\n",
              "  )\n",
              "  (joiner): RecursiveScriptModule(\n",
              "    original_name=Joiner\n",
              "    (linear): RecursiveScriptModule(original_name=Linear)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = data.DataLoader(test_dataset, batch_size=5, shuffle=False, collate_fn=lambda x: data_processing(x, 'test'))\n",
        "spectrograms, labels, input_lengths, label_lengths = next(iter(loader))\n",
        "predictions = get_transducer_predictions(\n",
        "    model, spectrograms, input_lengths,\n",
        "    labels, label_lengths\n",
        ")\n",
        "predictions"
      ],
      "metadata": {
        "id": "mu-sVO4Hi-k8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e7570f97-f2cd-418f-bb9c-840bf591bd7f",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:14.766148Z",
          "iopub.execute_input": "2023-11-27T11:34:14.766540Z",
          "iopub.status.idle": "2023-11-27T11:34:18.497730Z",
          "shell.execute_reply.started": "2023-11-27T11:34:14.766505Z",
          "shell.execute_reply": "2023-11-27T11:34:18.496845Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        ground_truth  \\\n",
              "0  he hoped there would be stew for dinner turnip...   \n",
              "1         stuff it into you his belly counselled him   \n",
              "2  after early nightfall the yellow lamps would l...   \n",
              "3                 hello bertie any good in your mind   \n",
              "4  number ten fresh nelly is waiting on you good ...   \n",
              "\n",
              "                                          prediction       cer       wer  \n",
              "0  he hoped there would be stew for dinner turnip...  0.128049  0.241379  \n",
              "1           stuffed into you his belly counciled him  0.150000  0.428571  \n",
              "2  after early night fall the yellow lamps would ...  0.096154  0.315789  \n",
              "3              her about he and he good in your mind  0.324324  0.555556  \n",
              "4  none but den fresh now as waiting on you could...  0.250000  0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-195027d9-5024-449b-9a20-0814a5bc8af6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>prediction</th>\n",
              "      <th>cer</th>\n",
              "      <th>wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>he hoped there would be stew for dinner turnip...</td>\n",
              "      <td>he hoped there would be stew for dinner turnip...</td>\n",
              "      <td>0.128049</td>\n",
              "      <td>0.241379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stuff it into you his belly counselled him</td>\n",
              "      <td>stuffed into you his belly counciled him</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>after early nightfall the yellow lamps would l...</td>\n",
              "      <td>after early night fall the yellow lamps would ...</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hello bertie any good in your mind</td>\n",
              "      <td>her about he and he good in your mind</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>number ten fresh nelly is waiting on you good ...</td>\n",
              "      <td>none but den fresh now as waiting on you could...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-195027d9-5024-449b-9a20-0814a5bc8af6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-195027d9-5024-449b-9a20-0814a5bc8af6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-195027d9-5024-449b-9a20-0814a5bc8af6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c36b849-7390-47cb-bac6-3d7c21e554fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c36b849-7390-47cb-bac6-3d7c21e554fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c36b849-7390-47cb-bac6-3d7c21e554fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_values = [\n",
        "    {\n",
        "        \"gt\": \"he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fattened sauce\",\n",
        "        \"prediction\": \"he hoped there would be stew for dinner turnips and characts and bruised potatoes and fat much and pieces to be lateled out in the thick peppered flowerfacton sauce\"\n",
        "    },\n",
        "    {\n",
        "        \"gt\": \"stuff it into you his belly counselled him\",\n",
        "        \"prediction\": \"stuffed into you his belly counciled him\"\n",
        "    },\n",
        "    {\n",
        "        \"gt\": \"after early nightfall the yellow lamps would light up here and there the squalid quarter of the brothels\",\n",
        "        \"prediction\": \"after early night fall the yellow lamps would lie how peer and there the squalit quarter of the brothels\"\n",
        "    },\n",
        "    {\n",
        "        \"gt\": \"hello bertie any good in your mind\",\n",
        "        \"prediction\": \"her about he and he good in your mind\"\n",
        "    },\n",
        "    {\n",
        "        \"gt\": \"number ten fresh nelly is waiting on you good night husband\",\n",
        "        \"prediction\": \"none but den fresh now as waiting on you could night husband\"\n",
        "    }\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "_Udw1t9ii-k8",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:18.500172Z",
          "iopub.execute_input": "2023-11-27T11:34:18.500548Z",
          "iopub.status.idle": "2023-11-27T11:34:18.506312Z",
          "shell.execute_reply.started": "2023-11-27T11:34:18.500513Z",
          "shell.execute_reply": "2023-11-27T11:34:18.505302Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(5):\n",
        "    gt = predictions.iloc[index].ground_truth\n",
        "    prediction = predictions.iloc[index].prediction\n",
        "    assert gt == reference_values[index][\"gt\"]\n",
        "    assert prediction == reference_values[index][\"prediction\"]"
      ],
      "metadata": {
        "id": "g7Pk9s7ei-k8",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:18.507637Z",
          "iopub.execute_input": "2023-11-27T11:34:18.508031Z",
          "iopub.status.idle": "2023-11-27T11:34:18.522850Z",
          "shell.execute_reply.started": "2023-11-27T11:34:18.507997Z",
          "shell.execute_reply": "2023-11-27T11:34:18.522049Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train your model (10 points)"
      ],
      "metadata": {
        "id": "rKCR9BdFi-k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can launch training of the model you've just built. To get **4 points**, provide the curves for test loss, CER and WER from Weights & Biases.\n",
        "\n",
        "After training, you will get the test metric values on the hold-out test set. To get the rest **6 points**, try to pass the following thresholds:\n",
        "\n",
        "- 0.15 test CER\n",
        "- 0.3 test WER"
      ],
      "metadata": {
        "id": "MBEOtdeZi-k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, device: str, train_loader: data.DataLoader,\n",
        "          test_sample: List[torch.Tensor], criterion: nn.Module, optimizer:\n",
        "          torch.optim.Optimizer, epoch: int, eval_period: int = 100) -> None:\n",
        "    \"\"\"\n",
        "    :param model: an RNN-T model\n",
        "    :param device: \"gpu\" or \"cpu\"\n",
        "    :param train_loader: training data loader\n",
        "    :param test_sample: a sample from the test set to log preliminary inference metrics\n",
        "    :param criterion: the loss function\n",
        "    :param optimizer: the training optimizer\n",
        "    :param epoch: the current epoch number\n",
        "    :param eval_period: the number of iterations between evaluations\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    for batch_idx, _data in tqdm(enumerate(train_loader), total=data_len//train_loader.batch_size):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model.forward(spectrograms, input_lengths, labels, label_lengths)   # (batch, time, label_length, n_class)\n",
        "        output = F.log_softmax(output, dim=-1)\n",
        "\n",
        "        loss = criterion(\n",
        "            output,\n",
        "            labels,\n",
        "            input_lengths.to(device),\n",
        "            label_lengths.to(device)\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % eval_period == 0 or batch_idx == data_len:\n",
        "            wandb.log({'loss_train': loss.item()})\n",
        "\n",
        "            with torch.no_grad():\n",
        "                spectrograms, labels, input_lengths, label_lengths = test_sample\n",
        "                spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "                predictions = get_transducer_predictions(\n",
        "                    model, spectrograms, input_lengths,\n",
        "                    labels, label_lengths\n",
        "                )\n",
        "                output = model.forward(spectrograms, input_lengths, labels, label_lengths)\n",
        "                val_loss = criterion(\n",
        "                  output,\n",
        "                  labels,\n",
        "                  input_lengths.to(device),\n",
        "                  label_lengths.to(device)\n",
        "                )\n",
        "                wandb.log({'loss_val': val_loss.item()})\n",
        "                clear_output(wait=True)\n",
        "                print('\\nTrain Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\\tVal loss: {:.6f}'.format(\n",
        "                      epoch, batch_idx * len(spectrograms), data_len,\n",
        "                      100. * batch_idx / len(train_loader), loss.item(), val_loss.item()))\n",
        "                print(f\"cer: {predictions.cer.mean()}, wer: {predictions.wer.mean()}\")\n",
        "                display(predictions)\n",
        "                wandb.log({'cer_val': predictions.cer.mean()})\n",
        "                wandb.log({'wer_val': predictions.wer.mean()})\n",
        "                wandb.log({'val_predictions': wandb.Table(dataframe=predictions)})\n",
        "\n",
        "\n",
        "def test(model: nn.Module, device: str, test_loader: data.DataLoader,\n",
        "         criterion: nn.Module, epoch: int, total_steps: int = None,\n",
        "         log_predictions: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    :param model: an RNN-T model\n",
        "    :param device: \"gpu\" or \"cpu\"\n",
        "    :param test_loader: test data loader\n",
        "    :param criterion: the loss function\n",
        "    :param epoch: the current epoch number\n",
        "    :param total_steps: the number of test steps to perform. If None, the whole test set will be used for evaluation\n",
        "    :param log_predictions: if True, the predicted labels will be logged to the W&B dashboard\n",
        "    \"\"\"\n",
        "    print('Beginning eval...')\n",
        "    model.eval()\n",
        "    test_cer, test_wer, test_loss = [], [], []\n",
        "    test_predictions = []\n",
        "    if total_steps is None:\n",
        "        total_steps = len(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, _data in tqdm_notebook(enumerate(test_loader), total=total_steps):\n",
        "            if i == total_steps:\n",
        "                break\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "            output = model.forward(spectrograms, input_lengths, labels, label_lengths)\n",
        "            loss = criterion(\n",
        "              output,\n",
        "              labels,\n",
        "              input_lengths.to(device),\n",
        "              label_lengths.to(device)\n",
        "            )\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            predictions = get_transducer_predictions(\n",
        "                model, spectrograms, input_lengths,\n",
        "                labels, label_lengths\n",
        "            )\n",
        "            test_cer += list(predictions.cer)\n",
        "            test_wer += list(predictions.wer)\n",
        "            if log_predictions:\n",
        "                test_predictions.append(predictions)\n",
        "\n",
        "    avg_cer = np.mean(test_cer)\n",
        "    avg_wer = np.mean(test_wer)\n",
        "    avg_loss = np.mean(test_loss)\n",
        "\n",
        "    if total_steps < len(test_loader):\n",
        "        wandb.log({\n",
        "            'loss_test': avg_loss,\n",
        "            'avg_cer': avg_cer,\n",
        "            'avg_wer': avg_wer\n",
        "        })\n",
        "    else:\n",
        "        wandb.log({\n",
        "            'loss_test_final': avg_loss,\n",
        "            'avg_cer_final': avg_cer,\n",
        "            'avg_wer_final': avg_wer\n",
        "        })\n",
        "    if log_predictions:\n",
        "        wandb.log({'test_predictions': wandb.Table(dataframe=pd.concat(test_predictions, ignore_index=True))})\n",
        "\n",
        "    print('Epoch: {:d}, Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(\n",
        "        epoch, avg_loss, avg_cer, avg_wer))\n"
      ],
      "metadata": {
        "id": "6wyqZtQ8i-k9",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:18.524130Z",
          "iopub.execute_input": "2023-11-27T11:34:18.524465Z",
          "iopub.status.idle": "2023-11-27T11:34:18.546034Z",
          "shell.execute_reply.started": "2023-11-27T11:34:18.524439Z",
          "shell.execute_reply": "2023-11-27T11:34:18.545245Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU found! 🎉')\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print('Only CPU found! 💻')\n",
        "    device = 'cpu'\n",
        "\n",
        "# Hyperparameters for your model\n",
        "\n",
        "hparams = {\n",
        "    'model': {\n",
        "        'num_classes': len(tokenizer.char_map),\n",
        "        'input_dim': 80,\n",
        "        'num_encoder_layers': 4,\n",
        "        'num_decoder_layers': 1,\n",
        "        'encoder_hidden_state_dim': 320,\n",
        "        'decoder_hidden_state_dim': 512,\n",
        "        'output_dim': 512,\n",
        "        'encoder_is_bidirectional': True,\n",
        "        'encoder_dropout_p': 0.2,\n",
        "        'decoder_dropout_p': 0.2\n",
        "    },\n",
        "    'data': {\n",
        "        'batch_size': 2,\n",
        "        'epochs': 20,\n",
        "        'learning_rate': 1e-4\n",
        "    }\n",
        "}\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=hparams['data']['batch_size'],\n",
        "                               shuffle=True, collate_fn=lambda x: data_processing(x), **kwargs)\n",
        "\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=hparams['data']['batch_size'],\n",
        "                              shuffle=False, collate_fn=lambda x: data_processing(x, 'test'), **kwargs)\n",
        "\n"
      ],
      "metadata": {
        "id": "lOWGMWf9i-k-",
        "outputId": "7c12b5c1-6c9c-47d6-d6da-2f0f19d9c753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:18.546970Z",
          "iopub.execute_input": "2023-11-27T11:34:18.547249Z",
          "iopub.status.idle": "2023-11-27T11:34:18.565337Z",
          "shell.execute_reply.started": "2023-11-27T11:34:18.547226Z",
          "shell.execute_reply": "2023-11-27T11:34:18.564471Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU found! 🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNTransducer(**hparams['model'])\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "RPzsOxuai-k-",
        "outputId": "da563731-9db2-40fe-fadc-83e49bd434eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:18.566555Z",
          "iopub.execute_input": "2023-11-27T11:34:18.566825Z",
          "iopub.status.idle": "2023-11-27T11:34:23.594419Z",
          "shell.execute_reply.started": "2023-11-27T11:34:18.566802Z",
          "shell.execute_reply": "2023-11-27T11:34:23.593498Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNTransducer(\n",
              "  (encoder): EncoderRNNT(\n",
              "    (lstm): LSTM(80, 320, num_layers=4, dropout=0.2, bidirectional=True)\n",
              "    (output_proj): Linear(in_features=640, out_features=512, bias=True)\n",
              "  )\n",
              "  (decoder): DecoderRNNT(\n",
              "    (embedding): Embedding(30, 512)\n",
              "    (lstm): LSTM(512, 512, dropout=0.2)\n",
              "    (output_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "  )\n",
              "  (joiner): Joiner(\n",
              "    (linear): Linear(in_features=512, out_features=30, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"speech-transducer\",\n",
        "           group=\"base-architecture\",\n",
        "           id='91aexrqd',\n",
        "           config=hparams,\n",
        "           resume=\"must\")"
      ],
      "metadata": {
        "id": "0Y00qHnwi-k_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "c32a4652-3541-458f-f3bf-7f87194eb0e6",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:34:23.598693Z",
          "iopub.execute_input": "2023-11-27T11:34:23.598989Z",
          "iopub.status.idle": "2023-11-27T11:38:03.300187Z",
          "shell.execute_reply.started": "2023-11-27T11:34:23.598963Z",
          "shell.execute_reply": "2023-11-27T11:38:03.299327Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231202_194010-91aexrqd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd' target=\"_blank\">17 epochs run</a></strong> to <a href='https://wandb.ai/gregkseno/speech-transducer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gregkseno/speech-transducer' target=\"_blank\">https://wandb.ai/gregkseno/speech-transducer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd' target=\"_blank\">https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c13f213f6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=hparams['data']['learning_rate'])\n",
        "criterion = RNNTLoss(blank=tokenizer.get_symbol_index(BLANK_SYMBOL), reduction='mean')\n",
        "test_sample = next(iter(test_loader))\n",
        "\n",
        "last_epoch = 1\n",
        "if wandb.run.resumed:\n",
        "    print(f'Resuming /gregkseno/speech-transducer/{wandb.run.id}...')\n",
        "    api = wandb.Api()\n",
        "    run = api.run(f'/gregkseno/speech-transducer/{wandb.run.id}')\n",
        "    print('Looking for the latest model')\n",
        "    tar_files = filter(lambda file: file.name.endswith('.tar'), run.files())\n",
        "    epochs = list(map(lambda file: re.findall(r'\\d+', file.name), tar_files))\n",
        "    epochs = [int(item) for sublist in epochs for item in sublist]\n",
        "    last_epoch = max(epochs)\n",
        "    print('Loading the latest model...')\n",
        "    checkpoint_path = wandb.restore(f'{snapshot_dir}/model_epoch{last_epoch}.tar').name[:-len(f'model_epoch{last_epoch}.tar')]\n",
        "    utils.load_checkpoint(model, checkpoint_name=f'model_epoch{last_epoch}.tar', path=checkpoint_path, device=device)"
      ],
      "metadata": {
        "id": "A6HlgxA9i-k_",
        "execution": {
          "iopub.status.busy": "2023-11-27T11:44:09.258912Z",
          "iopub.execute_input": "2023-11-27T11:44:09.259328Z",
          "iopub.status.idle": "2023-11-27T11:45:28.236494Z",
          "shell.execute_reply.started": "2023-11-27T11:44:09.259289Z",
          "shell.execute_reply": "2023-11-27T11:45:28.235345Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f41d8c6-e5f9-4354-8192-f55a0141a717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming /gregkseno/speech-transducer/91aexrqd...\n",
            "Looking for the latest model\n",
            "Loading the latest model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm_notebook(range(last_epoch, hparams['data']['epochs'] + 1)):\n",
        "    train(model, device, train_loader, test_sample, criterion, optimizer, epoch, eval_period=50)\n",
        "    utils.save_checkpoint(model, checkpoint_name=f'model_epoch{epoch}.tar', path=snapshot_dir)\n",
        "    wandb.save(os.path.join(snapshot_dir, f'model_epoch{epoch}.tar'))\n",
        "    test(model, device, test_loader, criterion, epoch, total_steps=20, log_predictions=True)\n",
        "\n",
        "utils.save_checkpoint(model, checkpoint_name=f'model.tar')\n",
        "wandb.save('model.tar')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T11:45:49.619668Z",
          "iopub.execute_input": "2023-11-27T11:45:49.620024Z",
          "iopub.status.idle": "2023-11-27T14:50:57.756247Z",
          "shell.execute_reply.started": "2023-11-27T11:45:49.619995Z",
          "shell.execute_reply": "2023-11-27T14:50:57.754165Z"
        },
        "trusted": true,
        "id": "4LR5n9GCT8NL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665,
          "referenced_widgets": [
            "f45b8fc8b0e64ee1a9296a6cac275f6c",
            "9b726d413daa4dafa661388171fc8813",
            "7fd703594da941d194272bf910b2058c",
            "c0d90040ddbb47cea8dc5f7fd49fcea5",
            "39efa0f5e1f64458bd97cfa7331cfbd2",
            "7768defcfe7646bc9c464756004ed593",
            "e402da03abcb4589b21b552f4155419d",
            "6dabd7f82d2747d792cea5955f7de4d0",
            "7a5d3687c45a439cacabdc2bb788a87c",
            "4645482e7e5645929168a9f49c8d8f0c",
            "3837fc696228413e975f2be3f6522542",
            "d0105406646d4767be9837e83e540904",
            "d1c887fa822241458d2ccea1afe58c3d",
            "d89f97bcebcd44049f114422ede40633",
            "3edbbd96b34845229f46693a9f9f98be",
            "7020fde6a6fb4d2fb858480b9a1f0849",
            "bd50cc2e9ae948519fc2198fe2c0b8fe",
            "472316585d564b4eafd737b4224197eb",
            "685a92fddf4b44349badbfdd560f603c",
            "391224b0ce194270962e621b53be654d",
            "bb7b6181ad494dfd8795adfb6142694d",
            "a6a3a50987804bacb9294364d7f7d4f3",
            "d8f4bad7204347c98cd794ed88a4ff9f",
            "54428e04f0014a2baf495dcc909dfa8f",
            "faf8d5cf7f254a64b625c55380bd0a9b",
            "cb211843eac84cf6834ea5ab03442114",
            "3017efe450d1444e81c65489719e3f4c",
            "e02d748eeb0c4a0e89fe686160b9b7fe",
            "f3191f59ea6f42ae8bf1aa96f2b52c26",
            "44ff1f8bb3fe438fbe7eb4aa0bb67c4c",
            "02b45b2f85a34ab7b7cdde169e074028",
            "d737136e231c4eb58aef111bc9a2d1e0",
            "6c56ed86e32b43d8adb87da5be2fd1f0"
          ]
        },
        "outputId": "2eb111d8-95cb-489e-e50a-e51a4ddd94e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 20 [28500/28539 (100%)]\tTrain Loss: 16.537706\tVal loss: 17.003975\n",
            "cer: 0.18366778641939163, wer: 0.25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                        ground_truth  \\\n",
              "0  he hoped there would be stew for dinner turnip...   \n",
              "1         stuff it into you his belly counselled him   \n",
              "\n",
              "                                          prediction       cer    wer  \n",
              "0  he hoped there would be stew for dinner turnip...  0.239130  0.375  \n",
              "1            stuff it into you his belly council him  0.128205  0.125  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bf8b1d9-e91c-4f6f-877d-397641bab6e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>prediction</th>\n",
              "      <th>cer</th>\n",
              "      <th>wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>he hoped there would be stew for dinner turnip...</td>\n",
              "      <td>he hoped there would be stew for dinner turnip...</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stuff it into you his belly counselled him</td>\n",
              "      <td>stuff it into you his belly council him</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bf8b1d9-e91c-4f6f-877d-397641bab6e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5bf8b1d9-e91c-4f6f-877d-397641bab6e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5bf8b1d9-e91c-4f6f-877d-397641bab6e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74ec1cdc-49d0-479a-8bd0-83350352adcd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74ec1cdc-49d0-479a-8bd0-83350352adcd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74ec1cdc-49d0-479a-8bd0-83350352adcd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|█████████▉| 14251/14269 [1:20:18<00:09,  1.88it/s]\u001b[A\n",
            "100%|█████████▉| 14252/14269 [1:20:18<00:07,  2.19it/s]\u001b[A\n",
            "100%|█████████▉| 14253/14269 [1:20:18<00:06,  2.52it/s]\u001b[A\n",
            "100%|█████████▉| 14254/14269 [1:20:19<00:05,  2.76it/s]\u001b[A\n",
            "100%|█████████▉| 14255/14269 [1:20:19<00:04,  2.93it/s]\u001b[A\n",
            "100%|█████████▉| 14256/14269 [1:20:19<00:04,  2.90it/s]\u001b[A\n",
            "100%|█████████▉| 14257/14269 [1:20:20<00:03,  3.03it/s]\u001b[A\n",
            "100%|█████████▉| 14258/14269 [1:20:20<00:03,  3.00it/s]\u001b[A\n",
            "100%|█████████▉| 14259/14269 [1:20:20<00:03,  3.08it/s]\u001b[A\n",
            "100%|█████████▉| 14260/14269 [1:20:21<00:02,  3.04it/s]\u001b[A\n",
            "100%|█████████▉| 14261/14269 [1:20:21<00:02,  2.90it/s]\u001b[A\n",
            "100%|█████████▉| 14262/14269 [1:20:21<00:02,  2.70it/s]\u001b[A\n",
            "100%|█████████▉| 14263/14269 [1:20:22<00:02,  2.58it/s]\u001b[A\n",
            "100%|█████████▉| 14264/14269 [1:20:22<00:01,  2.55it/s]\u001b[A\n",
            "100%|█████████▉| 14265/14269 [1:20:23<00:01,  2.52it/s]\u001b[A\n",
            "100%|█████████▉| 14266/14269 [1:20:23<00:01,  2.52it/s]\u001b[A\n",
            "100%|█████████▉| 14267/14269 [1:20:23<00:00,  2.49it/s]\u001b[A\n",
            "100%|█████████▉| 14268/14269 [1:20:24<00:00,  2.54it/s]\u001b[A\n",
            "14270it [1:20:24,  2.96it/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning eval...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-daaf868e1eaf>:84: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i, _data in tqdm_notebook(enumerate(test_loader), total=total_steps):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8f4bad7204347c98cd794ed88a4ff9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Test set: Average loss: 12.6966, Average CER: 0.071492 Average WER: 0.1668\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20231202_194010-91aexrqd/files/model.tar']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, device, test_loader, criterion, epoch)"
      ],
      "metadata": {
        "id": "Dao_2Mj7i-lA",
        "execution": {
          "iopub.status.busy": "2023-11-27T14:51:00.828256Z",
          "iopub.execute_input": "2023-11-27T14:51:00.828654Z",
          "iopub.status.idle": "2023-11-27T15:02:54.799004Z",
          "shell.execute_reply.started": "2023-11-27T14:51:00.828616Z",
          "shell.execute_reply": "2023-11-27T15:02:54.797939Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "6578808e3f7942b78e3e55c50ad5bb03",
            "1c4e77302ebb476e83362e6cc917b54d",
            "9c8c2fdf022846be96c493d0efeaf0ca",
            "0493b5e9a6af413ca8acb5e641fdb137",
            "abfd2a60030f4f49a0cdd0fd2a333610",
            "3bc65be5498a4986ac5d58cf21b2e424",
            "95402fc4e7c2437e994cb8b1dfafc504",
            "2f15839bf2ae487d83057a43a78e1cf1",
            "01c8471902604d95978f8e31e53b4d06",
            "12fe4d99dd784796a6e4811f168a045e",
            "20879855f76f4219804ff2b3447297d3"
          ]
        },
        "outputId": "58713fbf-6bbc-442d-9825-3a21e61671c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning eval...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-daaf868e1eaf>:84: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i, _data in tqdm_notebook(enumerate(test_loader), total=total_steps):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1310 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6578808e3f7942b78e3e55c50ad5bb03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Test set: Average loss: 24.0252, Average CER: 0.141519 Average WER: 0.2902\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "7RcHTK7gt3OX",
        "execution": {
          "iopub.status.busy": "2023-11-27T14:50:57.759804Z",
          "iopub.status.idle": "2023-11-27T14:50:57.760252Z",
          "shell.execute_reply.started": "2023-11-27T14:50:57.760016Z",
          "shell.execute_reply": "2023-11-27T14:50:57.760038Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380,
          "referenced_widgets": [
            "6523c2bf95fc4bffad1a37cb34b1a1a8",
            "f95014a812464ac3853291c4f56b6881",
            "b79be5bdd6b144c4ac19547689e08d8e",
            "f0339d8c4b0045f59919db5878dbd37f",
            "06e38920210f41398d89d4a248608032",
            "2ef703d9c273420bbe3545727830066d",
            "681b31dbef4d4d8992b5dd2b57273944",
            "fe16b0ceb66d4b509a0fef6e5845a0a6"
          ]
        },
        "outputId": "10d40141-29bb-47c3-e6ad-a6ee563b981c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='128.430 MB of 128.430 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6523c2bf95fc4bffad1a37cb34b1a1a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_cer</td><td>█▁</td></tr><tr><td>avg_cer_final</td><td>▁</td></tr><tr><td>avg_wer</td><td>█▁</td></tr><tr><td>avg_wer_final</td><td>▁</td></tr><tr><td>cer_val</td><td>▅▇▄▂▄█▆▄▆▁▃▅▅▄▆▄▃▂▆▃▄▅▄▄▁█▆▃▂▇▃▇▆▆▄▁▇▆▆▆</td></tr><tr><td>loss_test</td><td>█▁</td></tr><tr><td>loss_test_final</td><td>▁</td></tr><tr><td>loss_train</td><td>▄▂▁▂▃▆▄▂▆▄▃▅▃▃▄▂▂▄▅▃▅▂▂▅▄▂▂▃▃▇▄▅▃▇▇█▄▆▃▂</td></tr><tr><td>loss_val</td><td>▆▅▃▃▄▅▄▁▄▄▂▄▅▅▄▅▄▇▇▆▅█▇▆▅▇▆▅▇█▅▄▄▅▄▄▃▄▄▃</td></tr><tr><td>wer_val</td><td>▇▆▅▂▃█▅▅▇▃▃▄▆▄▃▅▄▂▆▃▇▆▆▄▁▆▅▃▃▅▄█▇▆▅▂▆▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_cer</td><td>0.07149</td></tr><tr><td>avg_cer_final</td><td>0.14152</td></tr><tr><td>avg_wer</td><td>0.16683</td></tr><tr><td>avg_wer_final</td><td>0.29022</td></tr><tr><td>cer_val</td><td>0.18367</td></tr><tr><td>loss_test</td><td>12.69657</td></tr><tr><td>loss_test_final</td><td>24.02515</td></tr><tr><td>loss_train</td><td>16.53771</td></tr><tr><td>loss_val</td><td>17.00397</td></tr><tr><td>wer_val</td><td>0.25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">17 epochs run</strong> at: <a href='https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd' target=\"_blank\">https://wandb.ai/gregkseno/speech-transducer/runs/91aexrqd</a><br/>Synced 3 W&B file(s), 574 media file(s), 573 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231202_194010-91aexrqd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eaLkzrIRt3OX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}